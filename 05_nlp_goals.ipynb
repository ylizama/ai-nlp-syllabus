{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import operator\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "\n",
    "from datetime import date\n",
    "import matplotlib.dates as dates\n",
    "\n",
    "from nltk import ngrams\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "sns.set_context('paper')\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_signs = list(string.punctuation)\n",
    "punct_signs.append('…')\n",
    "punct_signs.append('¿')\n",
    "punct_signs.append('•')\n",
    "punct_signs.append('”')\n",
    "punct_signs.append('“')\n",
    "punct_signs.append('–')\n",
    "punct_signs.remove('&')\n",
    "punct_signs.append('∑')\n",
    "\n",
    "stop_words = stopwords.words('english') + ['also', 'could', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Country', 'Univeristy', 'G2RWorldRank', 'G2RNationalRank',\n",
       "       'QSWorldUniversityRanking2021', 'Program',\n",
       "       'SchoolOfferingCourseProgram', 'CourseDescription', 'Course Unit',\n",
       "       'CourseUnitGoals', 'CourseUnitOutcomes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/courses.csv')\n",
    "df = df.fillna(\"\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def clean_text(text):\n",
    "    for p in punct_signs:\n",
    "        text = text.replace(p, ' ')\n",
    "    clean_text = text.lower().split()\n",
    "    clean_text = [w for w in clean_text if w not in stop_words]\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 most frequently used ngrams in description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m is the number of top ngrams.\n",
    "def getNGrams(text, n, m):\n",
    "    h_dict = {}   \n",
    "    ngramas = list(ngrams(text, n))\n",
    "    for grams in ngramas:\n",
    "        words = ' '.join(grams).strip()\n",
    "        if words not in h_dict:\n",
    "            h_dict[words] = 0\n",
    "        h_dict[words] = h_dict[words] + 1\n",
    "        \n",
    "    sorted_dict = sorted(h_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top_values = list(islice(sorted_dict, m))\n",
    "    return [(r[0], r[1], round(r[1]/len(ngramas)*100,2)) for r in top_values]\n",
    "\n",
    "def printNgrams(data, m):\n",
    "    Ngrams = []\n",
    "    unigrams = getNGrams(data, 1, m)\n",
    "    bigrams = getNGrams(data, 2 , m)\n",
    "    trigrams = getNGrams(data, 3 , m)\n",
    "    for i in range(0,m):\n",
    "        Ngrams.append(unigrams[i] + bigrams[i] + trigrams[i])\n",
    "    df = pd.DataFrame(Ngrams, columns=['Unigrams', 'Absolute Freq', 'Relative Freq', \n",
    "                                       'Bigrams', 'Absolute Freq', 'Relative Freq', \n",
    "                                       'Trigrams', 'Absolute Freq', 'Relative Freq',]) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ' '.join(list(df['CourseUnitGoals']))\n",
    "data  = clean_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unigrams</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "      <th>Bigrams</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "      <th>Trigrams</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>76</td>\n",
       "      <td>2.10</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>27</td>\n",
       "      <td>0.74</td>\n",
       "      <td>artificial intelligence machine</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learning</td>\n",
       "      <td>45</td>\n",
       "      <td>1.24</td>\n",
       "      <td>healthcare data</td>\n",
       "      <td>22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>intelligence machine learning</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>students</td>\n",
       "      <td>36</td>\n",
       "      <td>0.99</td>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>participants understand 1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethical</td>\n",
       "      <td>35</td>\n",
       "      <td>0.96</td>\n",
       "      <td>e g</td>\n",
       "      <td>9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>ai machine learning</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>machine</td>\n",
       "      <td>27</td>\n",
       "      <td>0.74</td>\n",
       "      <td>science technology</td>\n",
       "      <td>8</td>\n",
       "      <td>0.22</td>\n",
       "      <td>use healthcare data</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>healthcare</td>\n",
       "      <td>27</td>\n",
       "      <td>0.74</td>\n",
       "      <td>data analysis</td>\n",
       "      <td>7</td>\n",
       "      <td>0.19</td>\n",
       "      <td>machine learning algorithms</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>design</td>\n",
       "      <td>26</td>\n",
       "      <td>0.72</td>\n",
       "      <td>provide students</td>\n",
       "      <td>6</td>\n",
       "      <td>0.17</td>\n",
       "      <td>provide professionally relevant</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>understanding</td>\n",
       "      <td>25</td>\n",
       "      <td>0.69</td>\n",
       "      <td>students learn</td>\n",
       "      <td>6</td>\n",
       "      <td>0.17</td>\n",
       "      <td>professionally relevant teaching</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>technology</td>\n",
       "      <td>25</td>\n",
       "      <td>0.69</td>\n",
       "      <td>big data</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>relevant teaching learning</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ai</td>\n",
       "      <td>25</td>\n",
       "      <td>0.69</td>\n",
       "      <td>intelligence machine</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>successful understanding utilisation</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>understand</td>\n",
       "      <td>24</td>\n",
       "      <td>0.66</td>\n",
       "      <td>decision making</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>develop healthcare data</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>engineering</td>\n",
       "      <td>23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>ethical aspects</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>healthcare data experts</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>skills</td>\n",
       "      <td>23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>skills knowledge</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14</td>\n",
       "      <td>data experts necessary</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>analysis</td>\n",
       "      <td>23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>societal challenges</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>experts necessary expertise</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>methods</td>\n",
       "      <td>23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>ai methods</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>pursue expand roles</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>policy</td>\n",
       "      <td>23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>state art</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>expand roles rapidly</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>social</td>\n",
       "      <td>23</td>\n",
       "      <td>0.63</td>\n",
       "      <td>participants understand</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>roles rapidly evolving</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>problems</td>\n",
       "      <td>22</td>\n",
       "      <td>0.61</td>\n",
       "      <td>understand 1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>rapidly evolving environment</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>systems</td>\n",
       "      <td>21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>policy analysis</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>understanding practical ethical</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>course</td>\n",
       "      <td>21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>ai machine</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>practical ethical considerations</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>knowledge</td>\n",
       "      <td>21</td>\n",
       "      <td>0.58</td>\n",
       "      <td>fundamental knowledge</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>ethical considerations relevant</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>science</td>\n",
       "      <td>19</td>\n",
       "      <td>0.52</td>\n",
       "      <td>self learning</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>relevant learning around</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>identify</td>\n",
       "      <td>19</td>\n",
       "      <td>0.52</td>\n",
       "      <td>ethical societal</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>learning around current</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>use</td>\n",
       "      <td>19</td>\n",
       "      <td>0.52</td>\n",
       "      <td>challenges ai</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>healthcare data create</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>society</td>\n",
       "      <td>17</td>\n",
       "      <td>0.47</td>\n",
       "      <td>leaders field</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>data create professional</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>challenges</td>\n",
       "      <td>17</td>\n",
       "      <td>0.47</td>\n",
       "      <td>healthcare systems</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>create professional network</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>research</td>\n",
       "      <td>17</td>\n",
       "      <td>0.47</td>\n",
       "      <td>work relevant</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>professional network like</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>relevant</td>\n",
       "      <td>17</td>\n",
       "      <td>0.47</td>\n",
       "      <td>use healthcare</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>network like minded</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>problem</td>\n",
       "      <td>16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>learning algorithms</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>like minded individuals</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>technologies</td>\n",
       "      <td>16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>module examine</td>\n",
       "      <td>4</td>\n",
       "      <td>0.11</td>\n",
       "      <td>minded individuals leaders</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>solutions</td>\n",
       "      <td>15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>objective course</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>individuals leaders field</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>different</td>\n",
       "      <td>15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>practical experience</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>leaders field healthcare</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>including</td>\n",
       "      <td>15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>data science</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>field healthcare data</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>concepts</td>\n",
       "      <td>15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>case studies</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>provide students skills</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>develop</td>\n",
       "      <td>15</td>\n",
       "      <td>0.41</td>\n",
       "      <td>deep learning</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>students skills knowledge</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>provide</td>\n",
       "      <td>14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>basic concepts</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>healthcare data provide</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>development</td>\n",
       "      <td>14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>engineering related</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>machine learning models</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>work</td>\n",
       "      <td>14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>life long</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>objective course provide</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>artificial</td>\n",
       "      <td>14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>ethical reasoning</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>course provide students</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>intelligence</td>\n",
       "      <td>14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>conflicts different</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>provide students practical</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>system</td>\n",
       "      <td>14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>based approach</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>students practical experience</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>practical</td>\n",
       "      <td>13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>social sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>human computer interaction</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>evaluate</td>\n",
       "      <td>13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>analysis methods</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>identify distinguish large</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>societal</td>\n",
       "      <td>13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>big datasets</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>distinguish large scale</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>current</td>\n",
       "      <td>13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>course students</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>large scale data</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>apply</td>\n",
       "      <td>13</td>\n",
       "      <td>0.36</td>\n",
       "      <td>potential solutions</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>scale data analysis</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>based</td>\n",
       "      <td>12</td>\n",
       "      <td>0.33</td>\n",
       "      <td>solutions problems</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>data analysis methods</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>learn</td>\n",
       "      <td>12</td>\n",
       "      <td>0.33</td>\n",
       "      <td>social ethical</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>analysis methods focusing</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>techniques</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>information security</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>methods focusing three</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>applications</td>\n",
       "      <td>11</td>\n",
       "      <td>0.30</td>\n",
       "      <td>problem solving</td>\n",
       "      <td>3</td>\n",
       "      <td>0.08</td>\n",
       "      <td>focusing three main</td>\n",
       "      <td>2</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unigrams  Absolute Freq  Relative Freq                  Bigrams  \\\n",
       "0            data             76           2.10         machine learning   \n",
       "1        learning             45           1.24          healthcare data   \n",
       "2        students             36           0.99  artificial intelligence   \n",
       "3         ethical             35           0.96                      e g   \n",
       "4         machine             27           0.74       science technology   \n",
       "5      healthcare             27           0.74            data analysis   \n",
       "6          design             26           0.72         provide students   \n",
       "7   understanding             25           0.69           students learn   \n",
       "8      technology             25           0.69                 big data   \n",
       "9              ai             25           0.69     intelligence machine   \n",
       "10     understand             24           0.66          decision making   \n",
       "11    engineering             23           0.63          ethical aspects   \n",
       "12         skills             23           0.63         skills knowledge   \n",
       "13       analysis             23           0.63      societal challenges   \n",
       "14        methods             23           0.63               ai methods   \n",
       "15         policy             23           0.63                state art   \n",
       "16         social             23           0.63  participants understand   \n",
       "17       problems             22           0.61             understand 1   \n",
       "18        systems             21           0.58          policy analysis   \n",
       "19         course             21           0.58               ai machine   \n",
       "20      knowledge             21           0.58    fundamental knowledge   \n",
       "21        science             19           0.52            self learning   \n",
       "22       identify             19           0.52         ethical societal   \n",
       "23            use             19           0.52            challenges ai   \n",
       "24        society             17           0.47            leaders field   \n",
       "25     challenges             17           0.47       healthcare systems   \n",
       "26       research             17           0.47            work relevant   \n",
       "27       relevant             17           0.47           use healthcare   \n",
       "28        problem             16           0.44      learning algorithms   \n",
       "29   technologies             16           0.44           module examine   \n",
       "30      solutions             15           0.41         objective course   \n",
       "31      different             15           0.41     practical experience   \n",
       "32      including             15           0.41             data science   \n",
       "33       concepts             15           0.41             case studies   \n",
       "34        develop             15           0.41            deep learning   \n",
       "35        provide             14           0.39           basic concepts   \n",
       "36    development             14           0.39      engineering related   \n",
       "37           work             14           0.39                life long   \n",
       "38     artificial             14           0.39        ethical reasoning   \n",
       "39   intelligence             14           0.39      conflicts different   \n",
       "40         system             14           0.39           based approach   \n",
       "41      practical             13           0.36          social sciences   \n",
       "42       evaluate             13           0.36         analysis methods   \n",
       "43       societal             13           0.36             big datasets   \n",
       "44        current             13           0.36          course students   \n",
       "45          apply             13           0.36      potential solutions   \n",
       "46          based             12           0.33       solutions problems   \n",
       "47          learn             12           0.33           social ethical   \n",
       "48     techniques             11           0.30     information security   \n",
       "49   applications             11           0.30          problem solving   \n",
       "\n",
       "    Absolute Freq  Relative Freq                              Trigrams  \\\n",
       "0              27           0.74       artificial intelligence machine   \n",
       "1              22           0.61         intelligence machine learning   \n",
       "2              14           0.39             participants understand 1   \n",
       "3               9           0.25                   ai machine learning   \n",
       "4               8           0.22                   use healthcare data   \n",
       "5               7           0.19           machine learning algorithms   \n",
       "6               6           0.17       provide professionally relevant   \n",
       "7               6           0.17      professionally relevant teaching   \n",
       "8               5           0.14            relevant teaching learning   \n",
       "9               5           0.14  successful understanding utilisation   \n",
       "10              5           0.14               develop healthcare data   \n",
       "11              5           0.14               healthcare data experts   \n",
       "12              5           0.14                data experts necessary   \n",
       "13              4           0.11           experts necessary expertise   \n",
       "14              4           0.11                   pursue expand roles   \n",
       "15              4           0.11                  expand roles rapidly   \n",
       "16              4           0.11                roles rapidly evolving   \n",
       "17              4           0.11          rapidly evolving environment   \n",
       "18              4           0.11       understanding practical ethical   \n",
       "19              4           0.11      practical ethical considerations   \n",
       "20              4           0.11       ethical considerations relevant   \n",
       "21              4           0.11              relevant learning around   \n",
       "22              4           0.11               learning around current   \n",
       "23              4           0.11                healthcare data create   \n",
       "24              4           0.11              data create professional   \n",
       "25              4           0.11           create professional network   \n",
       "26              4           0.11             professional network like   \n",
       "27              4           0.11                   network like minded   \n",
       "28              4           0.11               like minded individuals   \n",
       "29              4           0.11            minded individuals leaders   \n",
       "30              3           0.08             individuals leaders field   \n",
       "31              3           0.08              leaders field healthcare   \n",
       "32              3           0.08                 field healthcare data   \n",
       "33              3           0.08               provide students skills   \n",
       "34              3           0.08             students skills knowledge   \n",
       "35              3           0.08               healthcare data provide   \n",
       "36              3           0.08               machine learning models   \n",
       "37              3           0.08              objective course provide   \n",
       "38              3           0.08               course provide students   \n",
       "39              3           0.08            provide students practical   \n",
       "40              3           0.08         students practical experience   \n",
       "41              3           0.08            human computer interaction   \n",
       "42              3           0.08            identify distinguish large   \n",
       "43              3           0.08               distinguish large scale   \n",
       "44              3           0.08                      large scale data   \n",
       "45              3           0.08                   scale data analysis   \n",
       "46              3           0.08                 data analysis methods   \n",
       "47              3           0.08             analysis methods focusing   \n",
       "48              3           0.08                methods focusing three   \n",
       "49              3           0.08                   focusing three main   \n",
       "\n",
       "    Absolute Freq  Relative Freq  \n",
       "0               5           0.14  \n",
       "1               5           0.14  \n",
       "2               4           0.11  \n",
       "3               4           0.11  \n",
       "4               4           0.11  \n",
       "5               4           0.11  \n",
       "6               3           0.08  \n",
       "7               3           0.08  \n",
       "8               3           0.08  \n",
       "9               3           0.08  \n",
       "10              3           0.08  \n",
       "11              3           0.08  \n",
       "12              3           0.08  \n",
       "13              3           0.08  \n",
       "14              3           0.08  \n",
       "15              3           0.08  \n",
       "16              3           0.08  \n",
       "17              3           0.08  \n",
       "18              3           0.08  \n",
       "19              3           0.08  \n",
       "20              3           0.08  \n",
       "21              3           0.08  \n",
       "22              3           0.08  \n",
       "23              3           0.08  \n",
       "24              3           0.08  \n",
       "25              3           0.08  \n",
       "26              3           0.08  \n",
       "27              3           0.08  \n",
       "28              3           0.08  \n",
       "29              3           0.08  \n",
       "30              3           0.08  \n",
       "31              3           0.08  \n",
       "32              3           0.08  \n",
       "33              3           0.08  \n",
       "34              3           0.08  \n",
       "35              3           0.08  \n",
       "36              3           0.08  \n",
       "37              2           0.06  \n",
       "38              2           0.06  \n",
       "39              2           0.06  \n",
       "40              2           0.06  \n",
       "41              2           0.06  \n",
       "42              2           0.06  \n",
       "43              2           0.06  \n",
       "44              2           0.06  \n",
       "45              2           0.06  \n",
       "46              2           0.06  \n",
       "47              2           0.06  \n",
       "48              2           0.06  \n",
       "49              2           0.06  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfNgrams = printNgrams(data, 50)\n",
    "dfNgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 Most used verbs and adjectives in description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yadira/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yadira/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/yadira/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m is the number of top ngrams.\n",
    "def getNPartsOfSpeech(text, m, tag):\n",
    "    h_dict = {}   \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    #lemmatization and filtering allowed tags\n",
    "    filtered_tags = [wordnet_lemmatizer.lemmatize(pt[0], pos=\"v\") for pt in pos_tags if pt[1].startswith(tag)]\n",
    "    \n",
    "    for ft in filtered_tags:    \n",
    "        if ft not in h_dict:\n",
    "            h_dict[ft] = 0\n",
    "        h_dict[ft] += 1\n",
    "        \n",
    "    sorted_dict = sorted(h_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    top_values = list(islice(sorted_dict, m))\n",
    "    return [(r[0], r[1], round(r[1]/len(filtered_tags)*100,2)) for r in top_values]\n",
    "\n",
    "def printNPOS(data, m):\n",
    "    postags = []\n",
    "    \n",
    "    verbs = getNPartsOfSpeech(data, m, 'V')\n",
    "    verbs += [(None, None)] * (m - len(verbs))\n",
    "    \n",
    "    adjs = getNPartsOfSpeech(data, m , 'J')\n",
    "    adjs +=[(None, None)] * (m - len(adjs))\n",
    "    \n",
    "    nouns = getNPartsOfSpeech(data, m , 'N')\n",
    "    nouns +=[(None, None)] * (m - len(nouns))\n",
    "    \n",
    "    for i in range(0,m):\n",
    "        if all(verbs[i]) or all(adj[i]) or all(nouns[i]):\n",
    "            postags.append(verbs[i] + adjs[i] + nouns[i])\n",
    "    df = pd.DataFrame(postags, columns=['Verbs', 'Absolute Freq', 'Relative Freq', \n",
    "                                       'Adjectives', 'Absolute Freq', 'Relative Freq',\n",
    "                                        'Nouns', 'Absolute Freq', 'Relative Freq' ]) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ' '.join(list(df['CourseUnitGoals']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Verbs</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "      <th>Adjectives</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "      <th>Nouns</th>\n",
       "      <th>Absolute Freq</th>\n",
       "      <th>Relative Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>be</td>\n",
       "      <td>73</td>\n",
       "      <td>10.96</td>\n",
       "      <td>ethical</td>\n",
       "      <td>34</td>\n",
       "      <td>4.58</td>\n",
       "      <td>data</td>\n",
       "      <td>55</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>learn</td>\n",
       "      <td>24</td>\n",
       "      <td>3.60</td>\n",
       "      <td>social</td>\n",
       "      <td>22</td>\n",
       "      <td>2.96</td>\n",
       "      <td>machine</td>\n",
       "      <td>26</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>include</td>\n",
       "      <td>21</td>\n",
       "      <td>3.15</td>\n",
       "      <td>different</td>\n",
       "      <td>15</td>\n",
       "      <td>2.02</td>\n",
       "      <td>students</td>\n",
       "      <td>25</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>understand</td>\n",
       "      <td>19</td>\n",
       "      <td>2.85</td>\n",
       "      <td>practical</td>\n",
       "      <td>13</td>\n",
       "      <td>1.75</td>\n",
       "      <td>learn</td>\n",
       "      <td>25</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apply</td>\n",
       "      <td>17</td>\n",
       "      <td>2.55</td>\n",
       "      <td>artificial</td>\n",
       "      <td>13</td>\n",
       "      <td>1.75</td>\n",
       "      <td>engineer</td>\n",
       "      <td>24</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>have</td>\n",
       "      <td>13</td>\n",
       "      <td>1.95</td>\n",
       "      <td>current</td>\n",
       "      <td>13</td>\n",
       "      <td>1.75</td>\n",
       "      <td>skills</td>\n",
       "      <td>23</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>use</td>\n",
       "      <td>11</td>\n",
       "      <td>1.65</td>\n",
       "      <td>societal</td>\n",
       "      <td>12</td>\n",
       "      <td>1.62</td>\n",
       "      <td>analysis</td>\n",
       "      <td>23</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>identify</td>\n",
       "      <td>11</td>\n",
       "      <td>1.65</td>\n",
       "      <td>specific</td>\n",
       "      <td>10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>understand</td>\n",
       "      <td>22</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>develop</td>\n",
       "      <td>10</td>\n",
       "      <td>1.50</td>\n",
       "      <td>relevant</td>\n",
       "      <td>9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>course</td>\n",
       "      <td>21</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>make</td>\n",
       "      <td>9</td>\n",
       "      <td>1.35</td>\n",
       "      <td>able</td>\n",
       "      <td>9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>challenge</td>\n",
       "      <td>21</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>address</td>\n",
       "      <td>8</td>\n",
       "      <td>1.20</td>\n",
       "      <td>professional</td>\n",
       "      <td>9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>methods</td>\n",
       "      <td>21</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>consider</td>\n",
       "      <td>7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>fundamental</td>\n",
       "      <td>9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>technology</td>\n",
       "      <td>21</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>examine</td>\n",
       "      <td>7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>critical</td>\n",
       "      <td>9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>AI</td>\n",
       "      <td>20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>design</td>\n",
       "      <td>7</td>\n",
       "      <td>1.05</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>9</td>\n",
       "      <td>1.21</td>\n",
       "      <td>problems</td>\n",
       "      <td>19</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>solve</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>technical</td>\n",
       "      <td>8</td>\n",
       "      <td>1.08</td>\n",
       "      <td>knowledge</td>\n",
       "      <td>19</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>evaluate</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>big</td>\n",
       "      <td>8</td>\n",
       "      <td>1.08</td>\n",
       "      <td>policy</td>\n",
       "      <td>18</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>need</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>various</td>\n",
       "      <td>8</td>\n",
       "      <td>1.08</td>\n",
       "      <td>design</td>\n",
       "      <td>17</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>relate</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>basic</td>\n",
       "      <td>8</td>\n",
       "      <td>1.08</td>\n",
       "      <td>field</td>\n",
       "      <td>17</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>support</td>\n",
       "      <td>6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>appropriate</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>society</td>\n",
       "      <td>16</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>lead</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>such</td>\n",
       "      <td>7</td>\n",
       "      <td>0.94</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>16</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>involve</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>scientific</td>\n",
       "      <td>6</td>\n",
       "      <td>0.81</td>\n",
       "      <td>approach</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>base</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>legal</td>\n",
       "      <td>6</td>\n",
       "      <td>0.81</td>\n",
       "      <td>concepts</td>\n",
       "      <td>15</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>work</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>other</td>\n",
       "      <td>6</td>\n",
       "      <td>0.81</td>\n",
       "      <td>solutions</td>\n",
       "      <td>14</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>give</td>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>potential</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>science</td>\n",
       "      <td>14</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>build</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>interdisciplinary</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>development</td>\n",
       "      <td>14</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>demonstrate</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>broad</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>model</td>\n",
       "      <td>13</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>take</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>successful</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>research</td>\n",
       "      <td>13</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>provide</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>global</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>systems</td>\n",
       "      <td>13</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>select</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>complex</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>problem</td>\n",
       "      <td>13</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>write</td>\n",
       "      <td>4</td>\n",
       "      <td>0.60</td>\n",
       "      <td>important</td>\n",
       "      <td>5</td>\n",
       "      <td>0.67</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>13</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Verbs  Absolute Freq  Relative Freq         Adjectives  \\\n",
       "0            be             73          10.96            ethical   \n",
       "1         learn             24           3.60             social   \n",
       "2       include             21           3.15          different   \n",
       "3    understand             19           2.85          practical   \n",
       "4         apply             17           2.55         artificial   \n",
       "5          have             13           1.95            current   \n",
       "6           use             11           1.65           societal   \n",
       "7      identify             11           1.65           specific   \n",
       "8       develop             10           1.50           relevant   \n",
       "9          make              9           1.35               able   \n",
       "10      address              8           1.20       professional   \n",
       "11     consider              7           1.05        fundamental   \n",
       "12      examine              7           1.05           critical   \n",
       "13       design              7           1.05         healthcare   \n",
       "14        solve              6           0.90          technical   \n",
       "15     evaluate              6           0.90                big   \n",
       "16         need              6           0.90            various   \n",
       "17       relate              6           0.90              basic   \n",
       "18      support              6           0.90        appropriate   \n",
       "19         lead              5           0.75               such   \n",
       "20      involve              5           0.75         scientific   \n",
       "21         base              5           0.75              legal   \n",
       "22         work              5           0.75              other   \n",
       "23         give              5           0.75          potential   \n",
       "24        build              4           0.60  interdisciplinary   \n",
       "25  demonstrate              4           0.60              broad   \n",
       "26         take              4           0.60         successful   \n",
       "27      provide              4           0.60             global   \n",
       "28       select              4           0.60            complex   \n",
       "29        write              4           0.60          important   \n",
       "\n",
       "    Absolute Freq  Relative Freq         Nouns  Absolute Freq  Relative Freq  \n",
       "0              34           4.58          data             55           2.75  \n",
       "1              22           2.96       machine             26           1.30  \n",
       "2              15           2.02      students             25           1.25  \n",
       "3              13           1.75         learn             25           1.25  \n",
       "4              13           1.75      engineer             24           1.20  \n",
       "5              13           1.75        skills             23           1.15  \n",
       "6              12           1.62      analysis             23           1.15  \n",
       "7              10           1.35    understand             22           1.10  \n",
       "8               9           1.21        course             21           1.05  \n",
       "9               9           1.21     challenge             21           1.05  \n",
       "10              9           1.21       methods             21           1.05  \n",
       "11              9           1.21    technology             21           1.05  \n",
       "12              9           1.21            AI             20           1.00  \n",
       "13              9           1.21      problems             19           0.95  \n",
       "14              8           1.08     knowledge             19           0.95  \n",
       "15              8           1.08        policy             18           0.90  \n",
       "16              8           1.08        design             17           0.85  \n",
       "17              8           1.08         field             17           0.85  \n",
       "18              7           0.94       society             16           0.80  \n",
       "19              7           0.94    healthcare             16           0.80  \n",
       "20              6           0.81      approach             15           0.75  \n",
       "21              6           0.81      concepts             15           0.75  \n",
       "22              6           0.81     solutions             14           0.70  \n",
       "23              5           0.67       science             14           0.70  \n",
       "24              5           0.67   development             14           0.70  \n",
       "25              5           0.67         model             13           0.65  \n",
       "26              5           0.67      research             13           0.65  \n",
       "27              5           0.67       systems             13           0.65  \n",
       "28              5           0.67       problem             13           0.65  \n",
       "29              5           0.67  intelligence             13           0.65  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printNPOS(data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
